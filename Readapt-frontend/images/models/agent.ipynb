{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmh3tuTcoD_y"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import StringTensorType\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skl2onnx onnx onnxruntime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps6FC5A312jw",
        "outputId": "39a852f5-69d0-4110-f497-d7328266831c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skl2onnx\n",
            "  Downloading skl2onnx-1.19.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.12/dist-packages (from skl2onnx) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->skl2onnx) (3.6.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading skl2onnx-1.19.1-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, onnx, coloredlogs, skl2onnx, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.19.0 onnxruntime-1.23.0 skl2onnx-1.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('text_intents_dataset.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "texts, labels = zip(*data)"
      ],
      "metadata": {
        "id": "m8dGKsEbqL2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)\n",
        "label_names = list(label_encoder.classes_)\n",
        "print(\"Classes:\", label_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxSRsAynqOvn",
        "outputId": "e897b221-569d-48fa-96df-4dbba212f085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: [np.str_('cycle_font_next'), np.str_('cycle_font_prev'), np.str_('decrease_contrast'), np.str_('decrease_font'), np.str_('decrease_letter_spacing'), np.str_('decrease_line_spacing'), np.str_('decrease_word_spacing'), np.str_('increase_contrast'), np.str_('increase_font'), np.str_('increase_letter_spacing'), np.str_('increase_line_spacing'), np.str_('increase_word_spacing'), np.str_('other'), np.str_('undo_changes')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer(\n",
        "        lowercase=True,\n",
        "        max_features=300,    # keep small for ONNX size\n",
        "        stop_words='english'\n",
        "    )),\n",
        "    ('clf', LogisticRegression(\n",
        "        multi_class='multinomial',\n",
        "        solver='lbfgs',\n",
        "        max_iter=300,\n",
        "        C=3.0,\n",
        "        random_state=42\n",
        "    )),\n",
        "])\n",
        "\n",
        "pipeline.fit(texts, y)\n",
        "print(\"Train accuracy:\", pipeline.score(texts, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgefvVLrqRI7",
        "outputId": "fd692088-2a37-48e1-9ffd-2b8969c36ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.9593023255813954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = convert_sklearn(\n",
        "    pipeline,\n",
        "    initial_types=[('input', StringTensorType([None, 1]))],\n",
        "    options={id(pipeline): {'zipmap': False}}\n",
        ")\n",
        "with open(\"intent-classifier.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "print(\"Saved intent-classifier.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiUcj4jyqVqh",
        "outputId": "ba40804c-b7e7-48c0-b1f1-80a2360f7289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved intent-classifier.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"intent_labels.json\", \"w\") as f:\n",
        "    json.dump(label_names, f)\n",
        "\n",
        "vocab = pipeline.named_steps['vect'].vocabulary_"
      ],
      "metadata": {
        "id": "5k72wE7EqayY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_vocab = {idx: word for word, idx in vocab.items()}\n",
        "sorted_vocab = [inv_vocab[i] for i in range(len(inv_vocab))]\n",
        "with open(\"intent_vectorizer_vocab.json\", \"w\") as f:\n",
        "    json.dump(sorted_vocab, f)\n",
        "\n",
        "print(\"Saved intent_labels.json and intent_vectorizer_vocab.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb_KxwvFqdgF",
        "outputId": "72e19912-d89d-42ba-f320-54a72cabf892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved intent_labels.json and intent_vectorizer_vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(pipeline, \"intent_pipeline.joblib\")\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "9Je7MEfGqgJA",
        "outputId": "e0b33edc-ac1e-4268-e10e-9bfdd842232d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = joblib.load(\"intent_pipeline.joblib\")"
      ],
      "metadata": {
        "id": "XBnkTSNN1oBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = pipeline.named_steps[\"vect\"]          # CountVectorizer\n",
        "clf = pipeline.named_steps[\"clf\"]                  # LogisticRegression\n",
        "label_encoder = None                               # We used LabelEncoder earlier"
      ],
      "metadata": {
        "id": "7PPmhHyp2Hnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"intent_labels.json\", \"r\") as f:\n",
        "    label_names = json.load(f)\n",
        "\n",
        "vocab = vectorizer.vocabulary_"
      ],
      "metadata": {
        "id": "YNK3D5KG2MFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_vocab = {idx: tok for tok, idx in vocab.items()}\n",
        "ordered_vocab = [inv_vocab[i] for i in range(len(inv_vocab))]\n",
        "\n",
        "weights = {\n",
        "    \"labels\": label_names,\n",
        "    \"vocab\": ordered_vocab,\n",
        "    \"coef\": clf.coef_.tolist(),        # shape: [num_classes, vocab_size]\n",
        "    \"intercept\": clf.intercept_.tolist()\n",
        "}\n",
        "\n",
        "with open(\"intent_logreg_weights.json\", \"w\") as f:\n",
        "    json.dump(weights, f)\n",
        "\n",
        "print(\"Wrote intent_logreg_weights.json\")"
      ],
      "metadata": {
        "id": "Guws4vrl2OlJ",
        "outputId": "8634e6bf-110b-4639-909b-fdd985d54683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote intent_logreg_weights.json\n"
          ]
        }
      ]
    }
  ]
}